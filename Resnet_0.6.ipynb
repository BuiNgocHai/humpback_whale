{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "MODEL_NAME = 'Resnet50'\n",
    "TRAIN = '/home/vicker/Documents/Hampback_Whale/train/'\n",
    "TEST = '/home/vicker/Documents/Hampback_Whale/test/'\n",
    "LABELS = 'train.csv'\n",
    "SAMPLE_SUB = 'sample_submission.csv'\n",
    "BBOX = '/home/vicker/Documents/Hampback_Whale/p2h/bounding_boxes.csv'\n",
    "# Backbone architecture\n",
    "arch = resnet50\n",
    "# Number of workers for data preprocessing\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicker/.local/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(LABELS).set_index('Image')\n",
    "new_whale_df = df[df.Id == \"new_whale\"]\n",
    "train_df = df[~(df.Id == \"new_whale\")]\n",
    "unique_labels = np.unique(train_df.Id.values)\n",
    "\n",
    "labels_dict = dict()\n",
    "labels_list = []\n",
    "\n",
    "for i in range(len(unique_labels)):\n",
    "    labels_dict[unique_labels[i]] = i\n",
    "    labels_list.append(unique_labels[i])\n",
    "print(\"Number of classes: {}\".format(len(unique_labels)))\n",
    "train_df.Id = train_df.Id.apply(lambda x: labels_dict[x])\n",
    "train_labels = np.asarray(train_df.Id.values)\n",
    "test_names = [f for f in os.listdir(TEST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val: 15697 1000\n",
      "Train classes 5004\n",
      "Val classes 819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['image_name'] = train_df.index\n",
    "bbox_df = pd.read_csv(BBOX).set_index('Image')\n",
    "\n",
    "rs = np.random.RandomState(42) # set random seed to be equal to the sense of life\n",
    "perm = rs.permutation(len(train_df))\n",
    "\n",
    "tr_n = train_df['image_name'].values\n",
    "# Yes, we will validate on the subset of training data\n",
    "val_n = train_df['image_name'].values[perm][:1000]\n",
    "\n",
    "print('Train/val:', len(tr_n), len(val_n))\n",
    "print('Train classes', len(train_df.loc[tr_n].Id.unique()))\n",
    "print('Val classes', len(train_df.loc[val_n].Id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWIDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.train_df = train_df\n",
    "        super().__init__(fnames, transform, path)\n",
    "\n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        bbox = bbox_df.loc[self.fnames[i]]\n",
    "        x0, y0, x1, y1 = bbox['x0'], bbox['y0'], bbox['x1'],  bbox['y1']\n",
    "        if not (x0 >= x1 or y0 >= y1):\n",
    "            img = img[y0:y1, x0:x1,:]\n",
    "        img = cv2.resize(img, (self.sz, self.sz))\n",
    "        return img\n",
    "\n",
    "    def get_y(self, i):\n",
    "        if (self.path == TEST): return 0\n",
    "        return self.train_df.loc[self.fnames[i]]['Id']\n",
    "\n",
    "    def get_c(self):\n",
    "        return len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLighting(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b, self.c = b, c\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand0(self.b)\n",
    "        self.store.c_rand = rand0(self.c)\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        if is_y and self.tfm_y != TfmType.PIXEL: return x  # add this line to fix the bug\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        c = -1 / (c - 1) if c < 0 else c + 1\n",
    "        x = lighting(x, b, c)\n",
    "        return x\n",
    "    \n",
    "def get_data(sz, batch_size):\n",
    "    \"\"\"\n",
    "    Read data and do augmentations\n",
    "    \"\"\"\n",
    "    aug_tfms = [RandomRotateZoom(deg=20, zoom=2, stretch=1),\n",
    "                RandomLighting(0.2, 0.2, tfm_y=TfmType.NO),\n",
    "                RandomBlur(blur_strengths=3,tfm_y=TfmType.NO),\n",
    "                RandomFlip(tfm_y=TfmType.NO)]\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.NO,\n",
    "                           aug_tfms=aug_tfms)\n",
    "    ds = ImageData.get_ds(HWIDataset, (tr_n[:-(len(tr_n) % batch_size)], TRAIN),\n",
    "                          (val_n, TRAIN), tfms, test=(test_names, TEST))\n",
    "    md = ImageData(\"./\", ds, batch_size, num_workers=num_workers, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/vicker/.torch/models/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [00:25<00:00, 4002313.79it/s]\n",
      "/home/vicker/.local/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "image_size = 384\n",
    "batch_size = 32\n",
    "md = get_data(image_size, batch_size)\n",
    "extra_fc_layers_size = []\n",
    "learn = ConvLearner.pretrained(arch, md, xtra_fc=extra_fc_layers_size) \n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layer groups: 3 \t(first 2 groups is pretrained backbone)\n",
      "This is our extra thin on top of the backbone Resnet50 architecture:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.5)\n",
       "  (2): Linear(in_features=4096, out_features=5004, bias=True)\n",
       "  (3): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of layer groups:', len(learn.get_layer_groups()), '\\t(first 2 groups is pretrained backbone)')\n",
    "print('This is our extra thin on top of the backbone Resnet50 architecture:')\n",
    "learn.get_layer_groups()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cc034e4ef04fd2970927114007beba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/490 [00:44<6:01:53, 44.40s/it, loss=9.13]"
     ]
    }
   ],
   "source": [
    "base_lr = 1e-4 # lr for the backbone\n",
    "fc_lr = 1e-3 # lr for the classifer\n",
    "\n",
    "lrs = [base_lr, base_lr, fc_lr]\n",
    "# Freeze backbone and train the classifier for 2 epochs\n",
    "learn.fit(lrs=lrs, n_cycle=2, cycle_len=None)\n",
    "\n",
    "# Unfreeze backbone and continue training for 9 epochs\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, n_cycle=16, cycle_len=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
